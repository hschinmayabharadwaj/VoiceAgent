{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a03c972",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chinmayabharadwajhs/day/final/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß† Using device: cpu\n",
      "\n",
      "üîπ Loading dataset from Hugging Face...\n",
      "‚úÖ Original splits: ['train']\n",
      "‚ö†Ô∏è Dataset has no test/validation split ‚Äî creating one manually...\n",
      "‚úÖ Dataset splits after fix: ['train', 'test']\n",
      "üßæ Using text column: 'formatted'\n",
      "‚ö†Ô∏è No labels found ‚Äî creating synthetic ones from keywords...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 52928/52928 [00:00<00:00, 206792.91 examples/s]\n",
      "Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13233/13233 [00:00<00:00, 156182.13 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä Label distribution ‚Äî Non-suicidal (0): 963, Suicidal (1): 51965\n",
      "\n",
      "‚ö° Fast Mode: using a small subset for quick training.\n",
      "\n",
      "üîπ Tokenizing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 50/50 [00:00<00:00, 5030.23 examples/s]\n",
      "Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:00<00:00, 1982.09 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Tokenization complete.\n",
      "\n",
      "üîπ Loading model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Model loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "# train_detector_fast_fixed.py\n",
    "# pip install transformers datasets torch scikit-learn accelerate\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import sklearn.metrics as metrics\n",
    "from datasets import load_dataset, DatasetDict\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer\n",
    ")\n",
    "\n",
    "# -------------------------------\n",
    "# ‚öôÔ∏è CONFIGURATION\n",
    "# -------------------------------\n",
    "MODEL_NAME = \"distilbert-base-uncased\"   # Lightweight BERT\n",
    "NUM_LABELS = 2                           # 0 = Non-suicidal, 1 = Suicidal\n",
    "FAST_MODE = True                         # Quick test mode\n",
    "TEST_SIZE = 0.2                          # 80% train, 20% test\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"üß† Using device: {device}\")\n",
    "\n",
    "# -------------------------------\n",
    "# 1Ô∏è‚É£ LOAD DATASET\n",
    "# -------------------------------\n",
    "print(\"\\nüîπ Loading dataset from Hugging Face...\")\n",
    "ds = load_dataset(\"cypsiSAS/transformed_Suicidal_ideation\")\n",
    "print(\"‚úÖ Original splits:\", list(ds.keys()))\n",
    "\n",
    "# Some Hugging Face datasets only have a \"train\" split\n",
    "if \"train\" in ds and len(ds.keys()) == 1:\n",
    "    print(\"‚ö†Ô∏è Dataset has no test/validation split ‚Äî creating one manually...\")\n",
    "    ds = ds[\"train\"].train_test_split(test_size=TEST_SIZE, seed=42)\n",
    "    ds = DatasetDict({\n",
    "        \"train\": ds[\"train\"],\n",
    "        \"test\": ds[\"test\"]\n",
    "    })\n",
    "print(\"‚úÖ Dataset splits after fix:\", list(ds.keys()))\n",
    "\n",
    "# Detect text column dynamically\n",
    "sample = ds[\"train\"][0]\n",
    "text_col = \"formatted\" if \"formatted\" in sample else (\"text\" if \"text\" in sample else \"content\")\n",
    "print(f\"üßæ Using text column: '{text_col}'\")\n",
    "\n",
    "# -------------------------------\n",
    "# 2Ô∏è‚É£ HANDLE LABELS\n",
    "# -------------------------------\n",
    "if \"labels\" not in ds[\"train\"].features and \"label\" not in ds[\"train\"].features:\n",
    "    print(\"‚ö†Ô∏è No labels found ‚Äî creating synthetic ones from keywords...\")\n",
    "\n",
    "    def create_labels(examples):\n",
    "        suicidal_keywords = [\n",
    "            \"kill myself\", \"end my life\", \"commit suicide\", \"want to die\",\n",
    "            \"suicidal\", \"end it all\", \"take my own life\", \"better off dead\",\n",
    "            \"not worth living\", \"want to disappear\", \"hurt myself\", \"self harm\"\n",
    "        ]\n",
    "        labels = []\n",
    "        for text in examples[text_col]:\n",
    "            text_lower = text.lower()\n",
    "            labels.append(1 if any(k in text_lower for k in suicidal_keywords) else 0)\n",
    "        return {\"labels\": labels}\n",
    "\n",
    "    ds = ds.map(create_labels, batched=True)\n",
    "else:\n",
    "    label_col = \"label\" if \"label\" in ds[\"train\"].features else \"labels\"\n",
    "    if label_col != \"labels\":\n",
    "        ds = ds.rename_column(label_col, \"labels\")\n",
    "\n",
    "# Label distribution\n",
    "if \"labels\" in ds[\"train\"].features:\n",
    "    y = np.array(ds[\"train\"][\"labels\"])\n",
    "    print(f\"\\nüìä Label distribution ‚Äî Non-suicidal (0): {np.sum(y==0)}, Suicidal (1): {np.sum(y==1)}\")\n",
    "\n",
    "# -------------------------------\n",
    "# 3Ô∏è‚É£ FAST MODE (subset for quick testing)\n",
    "# -------------------------------\n",
    "if FAST_MODE:\n",
    "    print(\"\\n‚ö° Fast Mode: using a small subset for quick training.\")\n",
    "    ds[\"train\"] = ds[\"train\"].select(range(min(50, len(ds[\"train\"]))))\n",
    "    ds[\"test\"] = ds[\"test\"].select(range(min(10, len(ds[\"test\"]))))\n",
    "\n",
    "# -------------------------------\n",
    "# 4Ô∏è‚É£ TOKENIZATION\n",
    "# -------------------------------\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "def preprocess(examples):\n",
    "    return tokenizer(\n",
    "        examples[text_col],\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "        max_length=256\n",
    "    )\n",
    "\n",
    "print(\"\\nüîπ Tokenizing...\")\n",
    "ds = ds.map(preprocess, batched=True)\n",
    "print(\"‚úÖ Tokenization complete.\")\n",
    "\n",
    "format_cols = [\"input_ids\", \"attention_mask\"]\n",
    "if \"labels\" in ds[\"train\"].features:\n",
    "    format_cols.append(\"labels\")\n",
    "ds.set_format(type=\"torch\", columns=format_cols)\n",
    "\n",
    "# -------------------------------\n",
    "# 5Ô∏è‚É£ MODEL INITIALIZATION\n",
    "# -------------------------------\n",
    "print(\"\\nüîπ Loading model...\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=NUM_LABELS)\n",
    "model.to(device)\n",
    "print(\"‚úÖ Model loaded successfully.\")\n",
    "\n",
    "# -------------------------------\n",
    "# 6Ô∏è‚É£ METRIC FUNCTION\n",
    "# -------------------------------\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    preds = np.argmax(logits, axis=-1)\n",
    "    precision = metrics.precision_score(labels, preds, zero_division=0)\n",
    "    recall = metrics.recall_score(labels, preds, zero_division=0)\n",
    "    f1 = metrics.f1_score(labels, preds, zero_division=0)\n",
    "    acc = metrics.accuracy_score(labels, preds)\n",
    "    return {\"accuracy\": acc, \"precision\": precision, \"recall\": recall, \"f1\": f1}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8299988a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------\n",
    "# 7Ô∏è‚É£ TRAINING ARGUMENTS\n",
    "# -------------------------------\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"out_model\",\n",
    "    do_eval=True,\n",
    "    eval_steps=10,\n",
    "    save_steps=20,\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=5,\n",
    "    fp16=torch.cuda.is_available(),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "37721ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------\n",
    "# 8Ô∏è‚É£ TRAINER SETUP\n",
    "# -------------------------------\n",
    "eval_split = \"validation\" if \"validation\" in ds else \"test\"\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=ds[\"train\"],\n",
    "    eval_dataset=ds[eval_split],\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf8ff036",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üöÄ Starting training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chinmayabharadwajhs/day/final/lib/python3.13/site-packages/torch/utils/data/dataloader.py:692: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='39' max='39' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [39/39 00:10, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.585400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.383300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.200100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.206400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.072100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.051100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>0.186900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chinmayabharadwajhs/day/final/lib/python3.13/site-packages/torch/utils/data/dataloader.py:692: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìà Evaluating model on unseen test data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chinmayabharadwajhs/day/final/lib/python3.13/site-packages/torch/utils/data/dataloader.py:692: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Evaluation results:\n",
      "Accuracy : 90.00%\n",
      "Precision: 90.00%\n",
      "Recall   : 100.00%\n",
      "F1 Score : 94.74%\n"
     ]
    }
   ],
   "source": [
    "# -------------------------------\n",
    "# 9Ô∏è‚É£ TRAIN & EVALUATE\n",
    "# -------------------------------\n",
    "print(\"\\nüöÄ Starting training...\")\n",
    "trainer.train()\n",
    "\n",
    "print(\"\\nüìà Evaluating model on unseen test data...\")\n",
    "results = trainer.evaluate(ds[eval_split])\n",
    "\n",
    "print(\"\\n‚úÖ Evaluation results:\")\n",
    "print(f\"Accuracy : {results['eval_accuracy']*100:.2f}%\")\n",
    "print(f\"Precision: {results['eval_precision']*100:.2f}%\")\n",
    "print(f\"Recall   : {results['eval_recall']*100:.2f}%\")\n",
    "print(f\"F1 Score : {results['eval_f1']*100:.2f}%\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "final",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
